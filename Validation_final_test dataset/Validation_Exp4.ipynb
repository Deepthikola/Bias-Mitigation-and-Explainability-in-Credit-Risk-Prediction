{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Experiment 4: Random Forest + Disparate Impact Remover - Retrain + Validate"
      ],
      "metadata": {
        "id": "8kfsDgPnsXs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_wrWvdescV8",
        "outputId": "89b54aab-7a7d-4563-a05c-0cbd3f08f585"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 0: Setup Environment\n",
        "!pip install aif360 shap scikit-learn pandas matplotlib seaborn joblib openpyxl BlackBoxAuditing --quiet"
      ],
      "metadata": {
        "id": "YO-fXW0Bse4i"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from aif360.datasets import StandardDataset\n",
        "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
        "from aif360.metrics import ClassificationMetric"
      ],
      "metadata": {
        "id": "wE0ZachFsmBY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load and Preprocess Training Dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Research_Thesis_Implementation/data_final/lendingclub_data.csv')\n",
        "# Use 7 features\n",
        "selected_cols = ['loan_status', 'annual_inc', 'term', 'grade', 'home_ownership', 'purpose', 'loan_amnt', 'zip_code']\n",
        "df = df[selected_cols].dropna()\n",
        "\n",
        "# Convert target to binary\n",
        "df['loan_status'] = df['loan_status'].apply(lambda x: 1 if x == 'Fully Paid' else 0)\n",
        "\n",
        "# Encode categorical features\n",
        "for col in ['term', 'grade', 'home_ownership', 'purpose', 'zip_code']:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "# Normalize income and loan amount\n",
        "df['annual_inc'] = StandardScaler().fit_transform(df[['annual_inc']])\n",
        "df['loan_amnt'] = StandardScaler().fit_transform(df[['loan_amnt']])\n"
      ],
      "metadata": {
        "id": "hmwALqa7sqAB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create AIF360 Dataset\n",
        "privileged_groups = [{'zip_code': 1}]\n",
        "unprivileged_groups = [{'zip_code': 0}]\n",
        "\n",
        "aif_data = StandardDataset(df,\n",
        "                           label_name='loan_status',\n",
        "                           favorable_classes=[1],\n",
        "                           protected_attribute_names=['zip_code'],\n",
        "                           privileged_classes=[[1]])"
      ],
      "metadata": {
        "id": "lRyYFdFhs1yi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Apply Disparate Impact Remover\n",
        "DIR = DisparateImpactRemover(repair_level=1.0)\n",
        "aif_data_transf = DIR.fit_transform(aif_data)"
      ],
      "metadata": {
        "id": "Sznbc9Yos4sM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train Random Forest on Transformed Data\n",
        "X = aif_data_transf.features\n",
        "y = aif_data_transf.labels.ravel()\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Save model as v2\n",
        "MODEL_PATH = '/content/drive/MyDrive/Research_Thesis_Implementation/Validation files & results/trained models/random_forest_disparateimpact_v2.pkl'\n",
        "joblib.dump(clf, MODEL_PATH)\n",
        "print(f'Model retrained and saved to: {MODEL_PATH}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qwuIMpus6ps",
        "outputId": "a1521eee-5b8d-46fc-fe1c-e389c83a368a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model retrained and saved to: /content/drive/MyDrive/Research_Thesis_Implementation/Validation files & results/trained models/random_forest_disparateimpact_v2.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HQOY2WuFpmC2"
      },
      "outputs": [],
      "source": [
        "# Step 6: Preprocess Test Dataset (same 7 features)\n",
        "def preprocess_testdata(df):\n",
        "    df = df.copy()\n",
        "    processed = pd.DataFrame()\n",
        "\n",
        "    # Annual income\n",
        "    scaler = StandardScaler()\n",
        "    processed['annual_inc'] = scaler.fit_transform(df[['annual_inc']].fillna(df['annual_inc'].median())).ravel()\n",
        "\n",
        "    # Term\n",
        "    le = LabelEncoder()\n",
        "    processed['term'] = le.fit_transform(df['term'].astype(str))\n",
        "\n",
        "    # Grade\n",
        "    le = LabelEncoder()\n",
        "    processed['grade'] = le.fit_transform(df['grade'].astype(str))\n",
        "\n",
        "    # Home ownership\n",
        "    le = LabelEncoder()\n",
        "    processed['home_ownership'] = le.fit_transform(df['home_ownership'].astype(str))\n",
        "\n",
        "    # Purpose\n",
        "    le = LabelEncoder()\n",
        "    processed['purpose'] = le.fit_transform(df['purpose'].astype(str))\n",
        "\n",
        "    # Loan amount\n",
        "    scaler = StandardScaler()\n",
        "    processed['loan_amnt'] = scaler.fit_transform(df[['loan_amnt']].fillna(df['loan_amnt'].median())).ravel()\n",
        "\n",
        "    # Protected attribute\n",
        "    le = LabelEncoder()\n",
        "    processed['zip_code'] = le.fit_transform(df['zip_code'].astype(str))\n",
        "\n",
        "    # Target\n",
        "    status_map = {\n",
        "        'Fully Paid': 1,\n",
        "        'Current': 1,\n",
        "        'Charged Off': 0,\n",
        "        'Default': 0,\n",
        "        'Late (31-120 days)': 0,\n",
        "        'Late (16-30 days)': 0,\n",
        "        'In Grace Period': 0\n",
        "    }\n",
        "    df['loan_status_mapped'] = df['loan_status'].map(status_map).fillna(0).astype(int)\n",
        "    processed['loan_status'] = df['loan_status_mapped']\n",
        "\n",
        "    return processed.dropna()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Validation Function\n",
        "def validate_on_testdata(df_processed, model):\n",
        "    privileged_groups = [{'zip_code': 1}]\n",
        "    unprivileged_groups = [{'zip_code': 0}]\n",
        "\n",
        "    aif_data = StandardDataset(df_processed,\n",
        "                               label_name='loan_status',\n",
        "                               favorable_classes=[1],\n",
        "                               protected_attribute_names=['zip_code'],\n",
        "                               privileged_classes=[[1]])\n",
        "    X = aif_data.features\n",
        "    y = aif_data.labels.ravel()\n",
        "    y_pred = model.predict(X)\n",
        "    y_prob = model.predict_proba(X)[:, 1]\n",
        "\n",
        "    print('\\nPERFORMANCE METRICS')\n",
        "    print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
        "    print(\"Precision:\", precision_score(y, y_pred))\n",
        "    print(\"Recall:\", recall_score(y, y_pred))\n",
        "    print(\"F1 Score:\", f1_score(y, y_pred))\n",
        "    print(\"AUC-ROC:\", roc_auc_score(y, y_prob))\n",
        "\n",
        "    print('\\nClassification Report:')\n",
        "    print(classification_report(y, y_pred, zero_division=0))\n",
        "\n",
        "    print('\\nFAIRNESS METRICS')\n",
        "    pred_dataset = aif_data.copy()\n",
        "    pred_dataset.labels = y_pred.reshape(-1, 1)\n",
        "    metric = ClassificationMetric(aif_data, pred_dataset,\n",
        "                                  unprivileged_groups=unprivileged_groups,\n",
        "                                  privileged_groups=privileged_groups)\n",
        "    print(\"Statistical Parity Difference:\", metric.statistical_parity_difference())\n",
        "    print(\"Disparate Impact:\", metric.disparate_impact())\n",
        "    print(\"Equal Opportunity Difference:\", metric.equal_opportunity_difference())\n",
        "    print(\"Average Odds Difference:\", metric.average_odds_difference())\n",
        "    print(\"Bias Amplification:\", metric.between_group_generalized_entropy_index())\n",
        "    print(\"Theil Index:\", metric.theil_index())\n",
        "\n",
        "    print('\\nEXPLAINABILITY METRICS')\n",
        "    explainer = shap.TreeExplainer(model)\n",
        "    shap_values = explainer.shap_values(X)\n",
        "    X_df = pd.DataFrame(X, columns=aif_data.feature_names)\n",
        "\n",
        "    if isinstance(shap_values, list):\n",
        "        shap.summary_plot(shap_values[1], X_df, show=False)\n",
        "    else:\n",
        "        shap.summary_plot(shap_values, X_df, show=False)\n",
        "\n",
        "    plt.title('SHAP Summary - Experiment 4 (Random Forest + DIR)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{RESULTS_DIR}/shap_exp4_testdata.png', dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'Accuracy': accuracy_score(y, y_pred),\n",
        "        'Precision': precision_score(y, y_pred),\n",
        "        'Recall': recall_score(y, y_pred),\n",
        "        'F1': f1_score(y, y_pred),\n",
        "        'AUC': roc_auc_score(y, y_prob),\n",
        "        'SPD': metric.statistical_parity_difference(),\n",
        "        'DI': metric.disparate_impact(),\n",
        "        'EOD': metric.equal_opportunity_difference(),\n",
        "        'AOD': metric.average_odds_difference(),\n",
        "        'BiasAmp': metric.between_group_generalized_entropy_index(),\n",
        "        'Theil': metric.theil_index()\n",
        "    }\n"
      ],
      "metadata": {
        "id": "QaDzO7gttD_X"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Run Validation\n",
        "RESULTS_DIR = '/content/drive/MyDrive/Research_Thesis_Implementation/Validation files & results/Validation Results'\n",
        "TESTDATA_PATH = '/content/drive/MyDrive/Research_Thesis_Implementation/Validation files & results/Validation dataset/TestData set.xlsx'\n",
        "\n",
        "test_df = pd.read_excel(TESTDATA_PATH)\n",
        "test_processed = preprocess_testdata(test_df)\n",
        "results = validate_on_testdata(test_processed, clf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HnXU7CDtGqQ",
        "outputId": "a957b833-a70a-4c1d-ab37-194a24079950"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PERFORMANCE METRICS\n",
            "Accuracy: 0.709258148370326\n",
            "Precision: 0.8355635615028306\n",
            "Recall: 0.7993599212210734\n",
            "F1 Score: 0.8170608958228485\n",
            "AUC-ROC: 0.601288521002208\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.27      0.32      0.29       939\n",
            "         1.0       0.84      0.80      0.82      4062\n",
            "\n",
            "    accuracy                           0.71      5001\n",
            "   macro avg       0.55      0.56      0.55      5001\n",
            "weighted avg       0.73      0.71      0.72      5001\n",
            "\n",
            "\n",
            "FAIRNESS METRICS\n",
            "Statistical Parity Difference: -0.25\n",
            "Disparate Impact: 0.75\n",
            "Equal Opportunity Difference: nan\n",
            "Average Odds Difference: nan\n",
            "Bias Amplification: 312.0625\n",
            "Theil Index: 0.2194213745899853\n",
            "\n",
            "EXPLAINABILITY METRICS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 9: Save Results\n",
        "results_df = pd.DataFrame([results])\n",
        "output_path = f'{RESULTS_DIR}/experiment4_validation_results_testdata.csv'\n",
        "results_df.to_csv(output_path, index=False)\n",
        "print(f'\\nResults saved to: {output_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxVWjQwptIKB",
        "outputId": "14885c6e-979d-4295-eaeb-c2063e28b74f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results saved to: /content/drive/MyDrive/Research_Thesis_Implementation/Validation files & results/Validation Results/experiment4_validation_results_testdata.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8EOKlYszwQ8y"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}